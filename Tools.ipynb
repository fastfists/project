{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start, we import all of the packages that we will need in this notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.integrate import quad\n",
    "from scipy.optimize import curve_fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 1: Preprocess The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding the features we will need to optimize to a DataFrame and then exporting to a csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the well production.csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_productions = pd.read_csv(\"well productions/well production.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we read in the csv file for each well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "datas = []\n",
    "for file in glob.glob(\"well productions/*\"):\n",
    "    if \"well production.csv\" not in file:\n",
    "        frame = pd.read_csv(file)\n",
    "        # Strip off the extra things on the end\n",
    "        frame[\"Name\"] = file[17:-4]\n",
    "        datas.append(frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calculates the well length for each well and adds the well length of each well to the DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def well_length(dataframe: pd.DataFrame):\n",
    "    dataframe[\"well length\"] = dataframe[\"easting\"].iloc[-1] - dataframe[\"easting\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calculates the number of frac stages for each well and adds the calculated value to the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def frac_stages(dataframe : pd.DataFrame):\n",
    "    dataframe[\"frac stages\"] = dataframe[dataframe[\"proppant weight (lbs)\"].isna() == False].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function sets proppant per stage as \"ppf.\" It will default to the maximum weight. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proppant_per_stage(dataframe: pd.DataFrame, find_min=False):\n",
    "    if find_min:\n",
    "        val = min(dataframe[\"proppant weight (lbs)\"])\n",
    "    else:\n",
    "        val = max(dataframe[\"proppant weight (lbs)\"])\n",
    "    dataframe[\"ppf\"] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function sets pump rate as \"pr.\" It will default to the maximum rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pump_rate(dataframe: pd.DataFrame, find_min=False):\n",
    "    if find_min:\n",
    "        val = min(dataframe[\"pump rate (cubic feet/min)\"])\n",
    "    else:\n",
    "        val = max(dataframe[\"pump rate (cubic feet/min)\"])\n",
    "    dataframe[\"pr\"] = val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function finds how many years the well will economically produce oil, under the assumption that up to 93 barrels of oil is economical. To arrive at this value we **NEED TO RATIONALIZE THIS VALUE** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def life_of_res(qi, D):\n",
    "    lifetime = 1/D*np.log(qi/93)\n",
    "    if lifetime < 0:\n",
    "        return 0\n",
    "    else: \n",
    "        return lifetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "exponential loss curve\n",
    "\n",
    "$ q(t) = q_ie^{-Dt} $\n",
    "\n",
    "Where $D$ is the decline rate and $q_i$ is the initial rate of production\n",
    "Exponential decline curve equation\n",
    "\n",
    "    Arguments:\n",
    "        t:  Number of months the well has been producing oil \n",
    "        qi: Float. Initial production rate when well first came online.\n",
    "        di: Float. Nominal decline rate (constant)\n",
    "        \n",
    "    Output: \n",
    "        Returns q, or the expected production rate at time t. Float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponential_loss(t, qi, D): \n",
    "    return qi*np.exp(-D*t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $ q(t) = \\frac{q_i}{(1+bDt)^{1.0/b}} $\n",
    " \n",
    " Hyperbolic decline curve equation\n",
    " \n",
    "    Arguments:\n",
    "        t:  Number of months the well has been producing oil\n",
    "        qi: Float. Initial production rate when well first came online.\n",
    "        b:  Float. Hyperbolic decline constant\n",
    "        di: Float. Nominal decline rate at time t=0\n",
    "    Output: \n",
    "        Returns q, or the expected production rate at time t. Float."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperbolic_loss(t, qi, b, di):\n",
    "    return qi/((1.0+b*di*t)**(1.0/b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function allows you to look at the first X months of production, and selects the highest production month as max initial production. It returns the max initial production in the first X months along with a series that contains the values of oil production for the first 12 months. \n",
    "    \n",
    "    Arguments:\n",
    "        number_first_months: int. Number of months from the point the well comes online\n",
    "        to compare to get the max initial production rate qi (this looks at multiple months\n",
    "        in case there is a production ramp-up)\n",
    "        \n",
    "        well_name: String. name of the well where we're attempting to get\n",
    "        the max volume from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_initial_production(number_first_months, well_name):\n",
    "    \n",
    "    row = well_productions.loc[well_productions[\"well name\"] == well_name]\n",
    "    val=0      \n",
    "    row = row.filter(regex='oil')\n",
    "    row=row.T.squeeze()\n",
    "    \n",
    "    for i in range(number_first_months):\n",
    "        val = max(row[i], val)\n",
    "\n",
    "    return val, row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below two functions find the defined integral of the fitted exponential and hyperbolic equations between 0 and the calculated life of the reservoir. Our team found that was easier to use an integral then implement the equation fround in the \"Hinge Basin\" notebook. \n",
    "\n",
    "$ N_p = \\int_0^{L_t} q(t)dt $ Where $N_p$ is total production and $L_t$ is the lifetime of the well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cumulative_exponential(qi, D):\n",
    "    return quad(exponential_loss, 0, life_of_res(qi, D), args=(qi,D))\n",
    "\n",
    "def get_cumulative_hyperbolic(qi, b, di):\n",
    "    return quad(hyperbolic_loss, 0, life_of_res(qi, di), args=(qi, b, di))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will add the expected lifetime of the well when using the exponential_loss function and the hyperbolic function then add the respective values to the dataframe. Following that, it will find the cumulative production with the least amount of error out of the two functions, and add that value to the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series=pd.Series(list(range(12)))\n",
    "def cum_production(dataframe: pd.DataFrame, find_min=False):\n",
    "    #find the name of the current well being examined\n",
    "    name = dataframe[\"Name\"][0]\n",
    "    #Set qi equal to the maximum production in the first 5 months of this well's lifespan, and row equal to the series of the \n",
    "    #first 12 months' production values\n",
    "    qi, row = get_max_initial_production(5, name)\n",
    "    \n",
    "    #Use the scipy curve_fit function to get the best possible exponential and hyperbolic curves\n",
    "    popt_exp, pcov_exp = curve_fit(exponential_loss, time_series, row, bounds=(0, [qi,20]))\n",
    "    popt_hyp, pcov_hyp=curve_fit(hyperbolic_loss, time_series, row,bounds=(0, [qi,2,20]))\n",
    "    \n",
    "    #Get the defined integral's value and error for both the exponential and hyperbolic curves\n",
    "    cp_exp = get_cumulative_exponential(*popt_exp)\n",
    "    cp_hyp = get_cumulative_hyperbolic(*popt_hyp)\n",
    "\n",
    "    #Set cumulative production to whichever defined integral has the least error\n",
    "    if cp_exp[1] < cp_hyp[1]: \n",
    "        cum_production = cp_exp[0]\n",
    "    else: \n",
    "        cum_production = cp_hyp[0]\n",
    "\n",
    "    #Add the respected calculated lifetimes for the exponential and hyperbolic curves to the dataframe then add the \n",
    "    #calculated cumulative production. \n",
    "    dataframe[\"lifetime_exp\"] = life_of_res(*popt_exp)\n",
    "    dataframe[\"lifetime_hyp\"] = life_of_res(popt_hyp[0], popt_hyp[2])\n",
    "    dataframe[\"cum_production\"] = cum_production\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we call all of the functions we wrote that add the values we will need to optimize to the DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "list(map(cum_production, datas))\n",
    "list(map(well_length, datas))\n",
    "list(map(frac_stages, datas))\n",
    "list(map(proppant_per_stage, datas))\n",
    "list(map(pump_rate, datas))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we drop the duplicate wells from the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "big_df = pd.concat(datas)\n",
    "## Removing duplicates makes graphing well locations significantly harder. Remove duplicates when regressing\n",
    "# big_df.drop_duplicates(subset=['Name'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we export our DataFrame to a new csv file so we no longer need to run preprocessing cells above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.to_csv(\"bigPoppa.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage2: Creating a model to predict cumulative output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a model that uses the features we added to the dataframe to predict cumulative output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We should finally be able to get to the fun stuff now ðŸ˜**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df = pd.read_csv(\"bigPoppa.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = big_df.drop_duplicates(subset=['Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    100.000000\n",
       "mean      35.994162\n",
       "std       11.099830\n",
       "min        0.072446\n",
       "25%       30.127467\n",
       "50%       37.639081\n",
       "75%       43.862433\n",
       "max       52.483608\n",
       "Name: lifetime_exp, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"lifetime_exp\"].describe() # should be measured in years"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply any sort of regression to our data, we must first clean our data and remove all non-numerical values that will not add any specific input into our final predictions. For this dataset, we see that the Names column along with any rows that have NaN/Infinity/Empty data should not be included in our model. Therefore, we will remove these anomalies from our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['Name'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(df):\n",
    "    df = df.dropna()\n",
    "    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n",
    "    return df[indices_to_keep].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = clean_dataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cleaning our data, we will use all but the cumulative production data in our dataframe to predict our cumulative production for each well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['cum_production', 'lifetime_hyp', 'lifetime_exp']\n",
    "#Changed this to just look at the values we are supposed to \n",
    "x = clean_data[['well length', 'frac stages', 'pr', 'ppf']] #clean_data.drop(drop_columns, axis = 1)\n",
    "y = clean_data['cum_production']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size=0.3, random_state=86)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(x_train, y_train)\n",
    "prediction = rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14059370852723152"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importances(model, features_df):\n",
    "    print(\"  Feature\".ljust(36) + \"  Score\")\n",
    "    print(\"-\"*60)\n",
    "    for i, feature in enumerate(model.feature_importances_):\n",
    "        print(\"| \", end=\"\")\n",
    "        print(f\"{features_df.columns[i]}\".ljust(36), end=\"|\")\n",
    "        print(f\"{feature}\".ljust(20), end=\"\")\n",
    "        print(\" |\")\n",
    "        print(\"-\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Feature                             Score\n",
      "------------------------------------------------------------\n",
      "| well length                         |0.25520496355924377  |\n",
      "------------------------------------------------------------\n",
      "| frac stages                         |0.31405733765415905  |\n",
      "------------------------------------------------------------\n",
      "| pr                                  |0.23824041536265664  |\n",
      "------------------------------------------------------------\n",
      "| ppf                                 |0.1924972834239405   |\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "feature_importances(rf, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<30x8648 sparse matrix of type '<class 'numpy.int64'>'\n",
       " \twith 22267 stored elements in Compressed Sparse Row format>,\n",
       " array([   0,   93,  186,  265,  336,  427,  508,  599,  690,  783,  868,\n",
       "         957, 1040, 1131, 1222, 1315, 1400, 1487, 1558, 1643, 1734, 1825,\n",
       "        1924, 2011, 2104, 2187, 2266, 2349, 2430, 2509, 2598, 2685, 2772,\n",
       "        2865, 2946, 3025, 3116, 3209, 3308, 3389, 3470, 3561, 3640, 3723,\n",
       "        3810, 3887, 3974, 4057, 4146, 4223, 4310, 4395, 4492, 4577, 4660,\n",
       "        4747, 4834, 4921, 4996, 5085, 5168, 5259, 5340, 5421, 5504, 5581,\n",
       "        5668, 5755, 5840, 5929, 6016, 6103, 6182, 6267, 6352, 6443, 6524,\n",
       "        6605, 6696, 6789, 6876, 6967, 7062, 7153, 7242, 7337, 7430, 7515,\n",
       "        7602, 7687, 7774, 7867, 7948, 8031, 8124, 8221, 8306, 8389, 8470,\n",
       "        8561, 8648], dtype=int32))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.decision_path(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we will see the differences between the regressor's predictions and the actual cumulative production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = 1;\n",
    "for diff in prediction-y_test:\n",
    "    print(str(cnt)+': ' + str(diff))\n",
    "    cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 3: Fancy graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph all well locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(data=big_df, x=\"easting\", y=\"northing\", size=\"lifetime_exp\")\n",
    "plt.ylabel(\"Northing\")\n",
    "plt.xlabel(\"Easting\")\n",
    "plt.title(\"Location of Horizontal wells, starting position\")\n",
    "plt.legend('', frameon=False) # remove the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_df.groupby([\"Name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change in water saturation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
